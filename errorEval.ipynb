{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from pcdet.config import cfg, cfg_from_yaml_file\n",
    "from pcdet.datasets import DatasetTemplate\n",
    "from pcdet.models import build_network, load_data_to_gpu\n",
    "from pcdet.utils import common_utils\n",
    "\n",
    "from pathlib import Path\n",
    "import yaml, os, glob\n",
    "import logging\n",
    "\n",
    "yaml_path = \"config.yaml\"\n",
    "with open(yaml_path, 'r') as f:\n",
    "    para_cfg = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "cfg_root = para_cfg['cfg_root']\n",
    "model_path = para_cfg['model_path']\n",
    "pcd_path = \"/home/ackerman/Workspace/OpenPCDet_ErrorModel/000000.bin\"\n",
    "data_path = \"/media/ackerman/Windows/Dataset/KITTI/object/training/\"\n",
    "\n",
    "results_path = \"/home/ackerman/Workspace/OpenPCDet_ErrorModel/results.txt\"\n",
    "\n",
    "cfg_from_yaml_file(cfg_root, cfg)\n",
    "logger = common_utils.create_logger(rank=\"Error\")\n",
    "\n",
    "class DemoDataset(DatasetTemplate):\n",
    "    def __init__(self, dataset_cfg, class_names, training=True, root_path=None, logger=None, ext='.bin'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_path:\n",
    "            dataset_cfg:\n",
    "            class_names:\n",
    "            training:\n",
    "            logger:\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            dataset_cfg=dataset_cfg, class_names=class_names, training=training, root_path=root_path, logger=logger\n",
    "        )\n",
    "        self.root_path = root_path\n",
    "        self.ext = ext\n",
    "        data_file_list = glob.glob(str(root_path / f'*{self.ext}')) if self.root_path.is_dir() else [self.root_path]\n",
    "\n",
    "        data_file_list.sort()\n",
    "        self.sample_file_list = data_file_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sample_file_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.ext == '.bin':\n",
    "            points = np.fromfile(self.sample_file_list[index], dtype=np.float32).reshape(-1, 4)\n",
    "        elif self.ext == '.npy':\n",
    "            points = np.load(self.sample_file_list[index])\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        input_dict = {\n",
    "            'points': points,\n",
    "            'frame_id': index,\n",
    "        }\n",
    "\n",
    "        data_dict = self.prepare_data(data_dict=input_dict)\n",
    "        return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_dataset = DemoDataset(\n",
    "    dataset_cfg=cfg.DATA_CONFIG, class_names=cfg.CLASS_NAMES, training=False,\n",
    "    root_path=Path(pcd_path), ext=\".bin\", logger=logger\n",
    ")\n",
    "model = build_network(model_cfg=cfg.MODEL, num_class=len(cfg.CLASS_NAMES), dataset=demo_dataset)\n",
    "model.load_params_from_file(filename=model_path, logger=logger, to_cpu=True)\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "results_file = open(results_path, 'w')\n",
    "num_frames = 7481\n",
    "num_car_labels = 0\n",
    "num_car_predictions = 0\n",
    "\n",
    "for i in range(num_frames):\n",
    "    print(f\"Processing {i}\")\n",
    "    pcd_path = os.path.join(data_path, \"velodyne\", f\"{str(i).zfill(6)}.bin\")\n",
    "    point_cloud = np.fromfile(pcd_path, dtype=np.float32)  \n",
    "    point_cloud = point_cloud.reshape(-1, 4)\n",
    "    input_dict = {\n",
    "        'points': point_cloud,\n",
    "        'frame_id': i,\n",
    "    }\n",
    "    data_dict = demo_dataset.prepare_data(data_dict=input_dict)\n",
    "    data_dict = demo_dataset.collate_batch([data_dict])\n",
    "    load_data_to_gpu(data_dict)\n",
    "    pred_dicts, _ = model.forward(data_dict)\n",
    "    pred_boxes = pred_dicts[0]['pred_boxes']\n",
    "    pred_scores = pred_dicts[0]['pred_scores']\n",
    "    pred_labels = pred_dicts[0]['pred_labels']\n",
    "    \n",
    "    label_path = os.path.join(data_path, \"label_2\", f\"{str(i).zfill(6)}.txt\")\n",
    "    car_positions = []\n",
    "    with open(label_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            line = line.strip().split(\" \")\n",
    "            if line[0] == \"Car\":\n",
    "                car_positions.append([float(line[11]), float(line[12]), float(line[13])])\n",
    "    \n",
    "    num_car_labels += len(car_positions)\n",
    "    for car_position in car_positions:\n",
    "        car_position = np.array([car_position[2], -car_position[0], -car_position[1]])\n",
    "        for pred_box, pred_score, pred_label in zip(pred_boxes, pred_scores, pred_labels):\n",
    "            pred_label = pred_label.cpu().detach().numpy()\n",
    "            if pred_label == 1:\n",
    "                pred_box = pred_box.cpu().detach().numpy()\n",
    "                pred_score = pred_score.cpu().detach().numpy()\n",
    "                error = (pred_box[:2] - car_position[:2])\n",
    "\n",
    "                if np.linalg.norm(error) < 1:\n",
    "                    results_file.write(f\"{i}\\t{error[0] - 0.25:.3f}\\t{error[1]:.3f}\\t{car_position[0]:.3f}\\t{car_position[1]:.3f}\\t{pred_score:.3f}\\n\")\n",
    "                    num_car_predictions += 1\n",
    "\n",
    "results_file.close()\n",
    "print(f\"Number of car labels: {num_car_labels}\")\n",
    "print(f\"Number of car predictions: {num_car_predictions}\")\n",
    "print(f\"Accuracy: {num_car_predictions / num_car_labels}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pcdet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
